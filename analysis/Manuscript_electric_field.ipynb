{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Applied electric field simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trajectory not included due to size limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "import mdtraj as md\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import MDAnalysis as mda\n",
    "import nglview as nv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import gmxapi as gmx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from manuscript import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\",context='paper',font_scale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NACHRA7_annotations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_note_dic = ef_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_note_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class POTENTIAL_XVG(object):\n",
    "    def __init__(self, location):\n",
    "        self.filename = location\n",
    "        self.read()\n",
    "        \n",
    "    def read(self):\n",
    "        self.potential = pd.read_table(self.filename,\n",
    "                                 header=None,\n",
    "                                 names=['coord','potential'],\n",
    "                                 sep='\\s+',\n",
    "                                 error_bad_lines=False,\n",
    "                                 skiprows=24)\n",
    "        for column in self.potential:\n",
    "            self.potential[column] = self.potential[column].astype(float)       \n",
    "#        self.potential['potential'] = self.potential['potential']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_md_dataframe():    \n",
    "    return pd.DataFrame(columns=list(['MD_name','replicate','frame','traj_time','system','id','ligand','note']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_metadata(traj_note, rep, ident, system, location, skip = default_skip):\n",
    "    rep_data = []\n",
    "    traj_note_split = traj_note.split('_')\n",
    "    top_location = '/' + \"init.pdb\"\n",
    "    traj_location = '/rep' + rep + '/' + \"ef.xtc\"\n",
    "    traj = mda.Universe(location + top_location,\n",
    "                        location + traj_location)         \n",
    "    md_name = traj_note_split[0]\n",
    "    ligand = traj_note_split[1:-1] ##in this case\n",
    "    timestep = 2\n",
    "    note = traj_note_split[-1]\n",
    "    n_frames = traj.trajectory.n_frames\n",
    "    ts = traj.trajectory.dt\n",
    "    for i in range(n_frames):\n",
    "        rep_data.append([md_name, rep, i,  ts * i, system, ident,ligand,note])\n",
    "\n",
    "    return rep_data\n",
    "    \n",
    "    \n",
    "meta_data = Parallel(n_jobs=num_cores)(delayed(append_metadata)(traj_note = traj_note_dic['traj_note'][0], \n",
    "                                                        rep = str(i%4 + 1),\n",
    "                                                        ident = i,\n",
    "                                                        system = i//4,\n",
    "                                                        location = traj_note_dic['save_location'][i//4],\n",
    "                                                       skip = traj_note_dic['skip'][i//4], \n",
    "                                               )\n",
    "                           for i in range(0, np.sum(traj_note_dic['rep'])))\n",
    "md_data = create_md_dataframe()\n",
    "for i in range(0,np.sum(traj_note_dic['rep'])):\n",
    "    md_data = md_data.append(pd.DataFrame(meta_data[i],columns=list(['MD_name','replicate','frame','traj_time','system','id','ligand','note'])),ignore_index=True)\n",
    "md_data['frame'] =md_data['frame'].apply(int)\n",
    "md_data['traj_time'] =md_data['traj_time'].apply(float)\n",
    "md_data['replicate'] =md_data['replicate'].apply(int)\n",
    "md_data['system'] = md_data['system'].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_potential(rep, location):\n",
    "    u = mda.Universe(location + '/init.pdb')\n",
    "    z_dim = u.dimensions[2]\n",
    "    gmx_run = gmx.commandline_operation('gmx_d',\n",
    "                      arguments=['potential','-sl','5000','-correct', '-tz', str(-z_dim/2)],\n",
    "                      input_files={\n",
    "                            '-f': location + '/rep' + rep + '/' + \"ef.xtc\",\n",
    "                            '-s': location + '/ef_double.tpr',\n",
    "                            '-n': location + '/index.ndx'\n",
    "                      },\n",
    "                      output_files={\n",
    "                            '-o': location + '/rep' + rep + '/' + '/potential.xvg',\n",
    "                            '-oc': location + '/rep' + rep + '/' + '/charge.xvg',\n",
    "                            '-of': location + '/rep' + rep + '/' + '/field.xvg'\n",
    "                      },\n",
    "                      stdin='0\\n'\n",
    "                     )\n",
    "    gmx_run.run()\n",
    "    print(gmx_run.output.erroroutput.result())\n",
    "\n",
    "    try:\n",
    "        for f in glob.glob(location + '/rep' + rep + '/'  + '/#*'):\n",
    "            os.remove(f)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "def append_potential(rep, location):\n",
    "    potential_data = []\n",
    "    get_potential(rep, location)\n",
    "    potential_data.append(POTENTIAL_XVG(location + '/rep' + rep + '/' + '/potential.xvg'))\n",
    "    return potential_data\n",
    "    \n",
    "potention_data = Parallel(n_jobs=num_cores)(delayed(append_potential)(rep = str(i%4 + 1),\n",
    "                                                        location = traj_note_dic['save_location'][i//4])\n",
    "                           for i in range(0, np.sum(traj_note_dic['rep'])))\n",
    "#xvg_data['potential'] = [x for x in np.hstack(potention_data) if x is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_potential(rep, location):\n",
    "    u = mda.Universe(location + '/init.pdb')\n",
    "    z_dim = u.dimensions[2]\n",
    "    gmx_run = gmx.commandline_operation('gmx_d',\n",
    "                      arguments=['potential','-sl','5000','-correct', '-tz', str(-z_dim/20), '-e', str(10000)],\n",
    "                      input_files={\n",
    "                            '-f': location + '/rep' + rep + '/' + \"ef.xtc\",\n",
    "                            '-s': location + '/ef_double.tpr',\n",
    "                            '-n': location + '/index.ndx'\n",
    "                      },\n",
    "                      output_files={\n",
    "                            '-o': location + '/rep' + rep + '/' + '/potential.xvg',\n",
    "                            '-oc': location + '/rep' + rep + '/' + '/charge.xvg',\n",
    "                            '-of': location + '/rep' + rep + '/' + '/field.xvg'\n",
    "                      },\n",
    "                      stdin='0\\n'\n",
    "                     )\n",
    "    gmx_run.run()\n",
    "    print(gmx_run.output.erroroutput.result())\n",
    "\n",
    "    try:\n",
    "        for f in glob.glob(location + '/rep' + rep + '/'  + '/#*'):\n",
    "            os.remove(f)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "def append_potential(rep, location):\n",
    "    potential_data = []\n",
    "    get_potential(rep, location)\n",
    "    potential_data.append(POTENTIAL_XVG(location + '/rep' + rep + '/' + '/potential.xvg'))\n",
    "    return potential_data\n",
    "    \n",
    "potention_data = Parallel(n_jobs=num_cores)(delayed(append_potential)(rep = str(i%4 + 1),\n",
    "                                                        location = traj_note_dic['save_location'][i//4])\n",
    "                           for i in range(0, np.sum(traj_note_dic['rep'])))\n",
    "#xvg_data['potential'] = [x for x in np.hstack(potention_data) if x is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_all_ion_info(ion, traj_note, rep, system, location):\n",
    "    def cartesian_to_cylinder(posx, posy, princ_x, princ_y):\n",
    "        return np.sqrt((posx - princ_x) ** 2 + (posy - princ_y) ** 2)\n",
    "    \n",
    "    ion_data = []\n",
    "    traj_note_split = traj_note.split('_')\n",
    "    top_location = location + '/' + \"init.pdb\"\n",
    "    traj_location = location + '/rep' + rep + '/' + \"ef.xtc\"\n",
    "    traj = mda.Universe(top_location,\n",
    "                        traj_location)\n",
    "\n",
    "    ions = traj.select_atoms('resname ' + ion)\n",
    "\n",
    "\n",
    "    princ_center_ch = np.mean(traj.select_atoms('resid 247 and name CA').positions[:5],axis=0)\n",
    "\n",
    "    for ts in traj.trajectory[:md_data[(md_data.system==system)&(md_data.replicate==eval(rep))]['frame'].max()+1]:\n",
    "        position_x = ions.positions.T[0]\n",
    "        position_y = ions.positions.T[1]\n",
    "        position_z = ions.positions.T[2] - princ_center_ch[2]\n",
    "#        position_r = cartesian_to_cylinder(position_x, position_y, princ_center_ch[0], princ_center_ch[1])\n",
    "\n",
    "        ion_data.append(np.asarray([position_x,\n",
    "                                    position_y,\n",
    "                                    position_z,\n",
    "                                    ]).T)\n",
    "    return ion_data\n",
    "\n",
    "\n",
    "for ion in ['SOD', 'CAL', 'CLA']:    \n",
    "    ion_data = Parallel(n_jobs=num_cores)(delayed(append_all_ion_info)(\n",
    "                                                        ion = ion,\n",
    "                                                        traj_note = traj_note_dic['traj_note'][0], \n",
    "                                                        rep = str(i%4 + 1),\n",
    "                                                        system = int(i/4),\n",
    "                                                        location = traj_note_dic['save_location'][i//4])\n",
    "                           for i in range(0, np.sum(traj_note_dic['rep'])))\n",
    "\n",
    "    ion_data_concat = [x for x in ion_data if x != []]\n",
    "    md_data[ion + '_data'] = [item for sublist in ion_data_concat for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = ['PNU_200', 'PNU_n200', 'PNU_0CA_200', 'PNU_0CA_n200', 'EPJ_200', 'EPJ_n200','PNU_noECD_200', 'PNU_noECD_n200', 'PNU_noICD_200', 'PNU_noICD_n200', 'PNU_E97A_200', 'PNU_E97A_n200']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for (i, (sys, df)) in enumerate(md_data.groupby(['system'])):\n",
    "    fig, axes = plt.subplots(1,4, figsize=(80,10), sharex=True, sharey=True, gridspec_kw={'wspace': 0})\n",
    "\n",
    "    for (ind, df), ax in zip(df.groupby(['replicate']),axes):\n",
    "\n",
    "        ion_all = df['SOD' + '_data'].apply(lambda x: np.array(x)).to_numpy()\n",
    "        ion_arr_all = np.concatenate(ion_all).reshape(df.shape[0],ion_all[0].shape[0],3).transpose((1,0,2))\n",
    "        for single_ion in ion_arr_all:\n",
    "            z_coord = single_ion.T[2].ravel()\n",
    "            mask_thr = z_coord.min() + 10\n",
    "            time = df['traj_time'].ravel()\n",
    "            #time = time[np.where(np.logical_and(z_coord>=60, z_coord<=120))]\n",
    "            time = np.ma.masked_where(z_coord<=mask_thr + 10, time)\n",
    "\n",
    "            z_coord = np.ma.masked_where(z_coord<=mask_thr + 10, z_coord)\n",
    "            ax.plot(time,\n",
    "                    z_coord)\n",
    "\n",
    "        ax.set_title('SOD rep ' + str(ind))\n",
    "        ax.set_ylim(-30,30)\n",
    "    #    ax.set_xlim(0,10000)\n",
    "    plt.savefig('./Figures/ef_' + system[i] + '.png',bbox_inches = 'tight', pad_inches=0.1, transparent=False)\n",
    "    #plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate Conductance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_middle = 3\n",
    "threshold_time = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sodium\n",
    "\n",
    "for (i, ((sys, ind), df)) in enumerate(md_data.groupby(['system','replicate'])):\n",
    "#    conduct_list = []\n",
    "    permeation_event = 0\n",
    "    df = md_data[(md_data.system == sys) & (md_data.replicate == ind)]\n",
    "    time = md_data[(md_data.system == sys) & (md_data.replicate == ind)].shape[0] * 40 / 1000\n",
    "    ion_all = df['SOD' + '_data'].apply(lambda x: np.array(x)).to_numpy()\n",
    "    ion_arr_all = np.concatenate(ion_all).reshape(df.shape[0],ion_all[0].shape[0],3).transpose((1,0,2))\n",
    "    for ion_single in ion_arr_all:\n",
    "        ion_z_single = ion_single.T[2]\n",
    "        mask = (ion_z_single >= -threshold_middle) & (ion_z_single <= threshold_middle)\n",
    "        if mask.any():\n",
    "            middle_points = np.argwhere((ion_z_single >= -threshold_middle) & (ion_z_single <= threshold_middle))\n",
    "            for middle_p in middle_points:\n",
    "                try:\n",
    "                    if np.sign(ion_z_single[middle_p-threshold_time]) != np.sign(ion_z_single[middle_p+threshold_time]):\n",
    "                        permeation_event += 1\n",
    "                        break\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "    columb_e_conv = 6.242E18\n",
    "    vmemb = 0.2\n",
    "    conductance = permeation_event / columb_e_conv / (time * 1e-9) / vmemb * 1e12\n",
    "    print('In sys', sys, 'in rep', ind, 'time', time, 'ns, permeation', permeation_event, 'conductance', conductance, 'pS')\n",
    "#    conduct_list.append(conductance)\n",
    "#    print('Conductance avg:', np.mean(conductance), '+-', np.var(conductance))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for (i, ((sys), sys_df)) in enumerate(md_data.groupby(['system'])):\n",
    "    conduct_list = []\n",
    "\n",
    "    for (j, (ind, df)) in enumerate(sys_df.groupby(['replicate'])):\n",
    "        permeation_event = 0\n",
    "        df = md_data[(md_data.system == sys) & (md_data.replicate == ind)]\n",
    "        time = md_data[(md_data.system == sys) & (md_data.replicate == ind)].shape[0] * 40 / 1000\n",
    "        ion_all = df['SOD' + '_data'].apply(lambda x: np.array(x)).to_numpy()\n",
    "        ion_arr_all = np.concatenate(ion_all).reshape(df.shape[0],ion_all[0].shape[0],3).transpose((1,0,2))\n",
    "        for ion_single in ion_arr_all:\n",
    "            ion_z_single = ion_single.T[2]\n",
    "            mask = (ion_z_single >= -threshold_middle) & (ion_z_single <= threshold_middle)\n",
    "            if mask.any():\n",
    "                middle_points = np.argwhere((ion_z_single >= -threshold_middle) & (ion_z_single <= threshold_middle))\n",
    "                for middle_p in middle_points:\n",
    "                    try:\n",
    "                        if np.sign(ion_z_single[middle_p-threshold_time]) != np.sign(ion_z_single[middle_p+threshold_time]):\n",
    "                            permeation_event += 1\n",
    "                            break\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "        columb_e_conv = 6.242E18\n",
    "        vmemb = 0.2\n",
    "        conductance = permeation_event / columb_e_conv / (time * 1e-9) / vmemb * 1e12\n",
    "        #print('In sys', sys, 'in rep', ind, 'time', time, 'ns, permeation', permeation_event, 'conductance', conductance, 'pS')\n",
    "        conduct_list.append(conductance)\n",
    "    print(system[sys])\n",
    "    print('Conductance avg:', np.mean(conduct_list), '+-',  np.std(conduct_list), 'pS')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_data['direction'] = md_data.system.apply(lambda x: 'up' if x%2 == 0 else 'down')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chloride\n",
    "for (i, ((sys, ind), df)) in enumerate(md_data.groupby(['system','replicate'])):\n",
    "    permeation_event = 0\n",
    "    df = md_data[(md_data.system == sys) & (md_data.replicate == ind)]\n",
    "    time = md_data[(md_data.system == sys) & (md_data.replicate == ind)].shape[0] * 40 / 1000\n",
    "    ion_all = df['CLA' + '_data'].apply(lambda x: np.array(x)).to_numpy()\n",
    "    ion_arr_all = np.concatenate(ion_all).reshape(df.shape[0],ion_all[0].shape[0],3).transpose((1,0,2))\n",
    "    for ion_single in ion_arr_all:\n",
    "        ion_z_single = ion_single.T[2]\n",
    "        mask = (ion_z_single >= -threshold_middle) & (ion_z_single <= threshold_middle)\n",
    "        if mask.any():\n",
    "            middle_points = np.argwhere((ion_z_single >= -threshold_middle) & (ion_z_single <= threshold_middle))\n",
    "            for middle_p in middle_points:\n",
    "                try:\n",
    "                    if np.sign(ion_z_single[middle_p-threshold_time]) != np.sign(ion_z_single[middle_p+threshold_time]):\n",
    "                        permeation_event += 1\n",
    "                        break\n",
    "                except:\n",
    "                    pass\n",
    "             \n",
    "    columb_e_conv = 6.242E18\n",
    "    vmemb = 0.2\n",
    "    conductance = permeation_event / columb_e_conv / (time * 1e-9) / vmemb * 1e12\n",
    "    print('In sys', sys, 'in rep', ind, 'time', time, 'ns, permeation', permeation_event, 'conductance', conductance, 'pS')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i, ((sys), sys_df)) in enumerate(md_data.groupby(['system'])):\n",
    "    conduct_list = []\n",
    "\n",
    "    for (j, (ind, df)) in enumerate(sys_df.groupby(['replicate'])):\n",
    "        permeation_event = 0\n",
    "        df = md_data[(md_data.system == sys) & (md_data.replicate == ind)]\n",
    "        time = md_data[(md_data.system == sys) & (md_data.replicate == ind)].shape[0] * 40 / 1000\n",
    "        ion_all = df['CLA' + '_data'].apply(lambda x: np.array(x)).to_numpy()\n",
    "        ion_arr_all = np.concatenate(ion_all).reshape(df.shape[0],ion_all[0].shape[0],3).transpose((1,0,2))\n",
    "        for ion_single in ion_arr_all:\n",
    "            ion_z_single = ion_single.T[2]\n",
    "            mask = (ion_z_single >= -threshold_middle) & (ion_z_single <= threshold_middle)\n",
    "            if mask.any():\n",
    "                middle_points = np.argwhere((ion_z_single >= -threshold_middle) & (ion_z_single <= threshold_middle))\n",
    "                for middle_p in middle_points:\n",
    "                    try:\n",
    "                        if np.sign(ion_z_single[middle_p-threshold_time]) != np.sign(ion_z_single[middle_p+threshold_time]):\n",
    "                            permeation_event += 1\n",
    "                            break\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "        columb_e_conv = 6.242E18\n",
    "        vmemb = 0.2\n",
    "        conductance = permeation_event / columb_e_conv / (time * 1e-9) / vmemb * 1e12\n",
    "        #print('In sys', sys, 'in rep', ind, 'time', time, 'ns, permeation', permeation_event, 'conductance', conductance, 'pS')\n",
    "        conduct_list.append(conductance)\n",
    "    print(system[sys])\n",
    "\n",
    "    print('Conductance avg:', np.mean(conduct_list), '+-',  np.std(conduct_list), 'pS')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for (i, ((sys), sys_df)) in enumerate(md_data.groupby(['system'])):\n",
    "    conduct_list = []\n",
    "\n",
    "    for (j, (ind, df)) in enumerate(sys_df.groupby(['replicate'])):\n",
    "        permeation_event = 0\n",
    "        df = md_data[(md_data.system == sys) & (md_data.replicate == ind)]\n",
    "        time = md_data[(md_data.system == sys) & (md_data.replicate == ind)].shape[0] * 40 / 1000\n",
    "        ion_all = df['CAL' + '_data'].apply(lambda x: np.array(x)).to_numpy()\n",
    "        ion_arr_all = np.concatenate(ion_all).reshape(df.shape[0],ion_all[0].shape[0],3).transpose((1,0,2))\n",
    "        for ion_single in ion_arr_all:\n",
    "            ion_z_single = ion_single.T[2]\n",
    "            mask = (ion_z_single >= -threshold_middle) & (ion_z_single <= threshold_middle)\n",
    "            if mask.any():\n",
    "                middle_points = np.argwhere((ion_z_single >= -threshold_middle) & (ion_z_single <= threshold_middle))\n",
    "                for middle_p in middle_points:\n",
    "                    try:\n",
    "                        if np.sign(ion_z_single[middle_p-threshold_time]) != np.sign(ion_z_single[middle_p+threshold_time]):\n",
    "                            permeation_event += 1\n",
    "                            break\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "        columb_e_conv = 6.242E18\n",
    "        vmemb = 0.2\n",
    "        conductance = permeation_event / columb_e_conv / (time * 1e-9) / vmemb * 1e12\n",
    "        #print('In sys', sys, 'in rep', ind, 'time', time, 'ns, permeation', permeation_event, 'conductance', conductance, 'pS')\n",
    "        conduct_list.append(conductance)\n",
    "    print(system[sys])\n",
    "\n",
    "    print('Conductance avg:', np.mean(conduct_list), '+-',  np.std(conduct_list), 'pS')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_data.to_pickle('data/ef.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_data = pd.read_pickle('data/ef.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_md_dataframe():    \n",
    "    return pd.DataFrame(columns=list(['MD_name','replicate','traj_time','system','id','ligand','note']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_note_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_metadata(traj_note, rep, ident, system, location, skip = default_skip):\n",
    "    rep_data = []\n",
    "    traj_note_split = traj_note.split('_')\n",
    "    top_location = '/' + \"init.pdb\"\n",
    "    traj_location = '/rep' + rep + '/' + \"ef.xtc\"\n",
    "    traj = mda.Universe(location + top_location,\n",
    "                        location + traj_location)         \n",
    "    md_name = traj_note_split[0]\n",
    "    if location.split('/')[-1] == '': \n",
    "        ligand = location.split('/')[-3]\n",
    "        note = location.split('/')[-2]\n",
    "    else:\n",
    "        ligand = location.split('/')[-2]\n",
    "        note = location.split('/')[-1]        \n",
    "\n",
    "    timestep = 2\n",
    "    n_frames = traj.trajectory.n_frames\n",
    "    ts = traj.trajectory.dt\n",
    "    rep_data.append([md_name, rep, ts * n_frames, system, ident,ligand,note])\n",
    "\n",
    "    return rep_data\n",
    "    \n",
    "    \n",
    "meta_data = Parallel(n_jobs=num_cores)(delayed(append_metadata)(traj_note = traj_note_dic['traj_note'][0], \n",
    "                                                        rep = str(i%4 + 1),\n",
    "                                                        ident = i,\n",
    "                                                        system = i//4,\n",
    "                                                        location = traj_note_dic['save_location'][i//4],\n",
    "                                                       skip = traj_note_dic['skip'][i//4], \n",
    "                                               )\n",
    "                           for i in range(0, np.sum(traj_note_dic['rep'])))\n",
    "ef_data = create_md_dataframe()\n",
    "for i in range(0,np.sum(traj_note_dic['rep'])):\n",
    "    ef_data = ef_data.append(pd.DataFrame(meta_data[i],columns=list(ef_data.columns)),ignore_index=True)\n",
    "ef_data['traj_time'] =ef_data['traj_time'].apply(float)\n",
    "ef_data['replicate'] =ef_data['replicate'].apply(int)\n",
    "ef_data['system'] = ef_data['system'].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_potential(rep, location):\n",
    "    u = mda.Universe(location + '/init.pdb')\n",
    "    z_dim = u.dimensions[2]\n",
    "    gmx_run = gmx.commandline_operation('gmx_d',\n",
    "                      arguments=['potential','-sl','5000','-correct', '-tz', str(-z_dim/2)],\n",
    "                      input_files={\n",
    "                            '-f': location + '/rep' + rep + '/' + \"ef.xtc\",\n",
    "                            '-s': location + '/ef_double.tpr',\n",
    "                            '-n': location + '/index.ndx'\n",
    "                      },\n",
    "                      output_files={\n",
    "                            '-o': location + '/rep' + rep + '/' + '/potential.xvg',\n",
    "                            '-oc': location + '/rep' + rep + '/' + '/charge.xvg',\n",
    "                            '-of': location + '/rep' + rep + '/' + '/field.xvg'\n",
    "                      },\n",
    "                      stdin='0\\n'\n",
    "                     )\n",
    "    gmx_run.run()\n",
    "    print(gmx_run.output.erroroutput.result())\n",
    "\n",
    "    try:\n",
    "        for f in glob.glob(location + '/rep' + rep + '/'  + '/#*'):\n",
    "            os.remove(f)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "def append_potential(rep, location):\n",
    "    potential_data = []\n",
    "    get_potential(rep, location)\n",
    "    potential_data.append(POTENTIAL_XVG(location + '/rep' + rep + '/' + '/potential.xvg'))\n",
    "    return potential_data\n",
    "    \n",
    "potention_data = Parallel(n_jobs=num_cores)(delayed(append_potential)(rep = str(i%4 + 1),\n",
    "                                                        location = traj_note_dic['save_location'][i//4])\n",
    "                           for i in range(0, np.sum(traj_note_dic['rep'])))\n",
    "ef_data['potential'] = [x for x in np.hstack(potention_data) if x is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_middle = 3\n",
    "threshold_time = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conductance_list = []\n",
    "for (i, ((sys, ind), df)) in enumerate(md_data.groupby(['system','replicate'])):\n",
    "#    conduct_list = []\n",
    "    permeation_event = 0\n",
    "    df = md_data[(md_data.system == sys) & (md_data.replicate == ind)]\n",
    "    time = md_data[(md_data.system == sys) & (md_data.replicate == ind)].shape[0] * 40 / 1000\n",
    "    ion_all = df['SOD' + '_data'].apply(lambda x: np.array(x)).to_numpy()\n",
    "    ion_arr_all = np.concatenate(ion_all).reshape(df.shape[0],ion_all[0].shape[0],3).transpose((1,0,2))\n",
    "    for ion_single in ion_arr_all:\n",
    "        ion_z_single = ion_single.T[2]\n",
    "        mask = (ion_z_single >= -threshold_middle) & (ion_z_single <= threshold_middle)\n",
    "        if mask.any():\n",
    "            middle_points = np.argwhere((ion_z_single >= -threshold_middle) & (ion_z_single <= threshold_middle))\n",
    "            for middle_p in middle_points:\n",
    "                try:\n",
    "                    if np.sign(ion_z_single[middle_p-threshold_time]) != np.sign(ion_z_single[middle_p+threshold_time]):\n",
    "                        permeation_event += 1\n",
    "                        break\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "    columb_e_conv = 6.242E18\n",
    "    vmemb = 0.2\n",
    "    conductance = permeation_event / columb_e_conv / (time * 1e-9) / vmemb * 1e12\n",
    "    conductance_list.append(conductance)\n",
    "ef_data['conductance_sod'] = conductance_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conductance_list = []\n",
    "for (i, ((sys, ind), df)) in enumerate(md_data.groupby(['system','replicate'])):\n",
    "#    conduct_list = []\n",
    "    permeation_event = 0\n",
    "    df = md_data[(md_data.system == sys) & (md_data.replicate == ind)]\n",
    "    time = md_data[(md_data.system == sys) & (md_data.replicate == ind)].shape[0] * 40 / 1000\n",
    "    ion_all = df['CLA' + '_data'].apply(lambda x: np.array(x)).to_numpy()\n",
    "    ion_arr_all = np.concatenate(ion_all).reshape(df.shape[0],ion_all[0].shape[0],3).transpose((1,0,2))\n",
    "    for ion_single in ion_arr_all:\n",
    "        ion_z_single = ion_single.T[2]\n",
    "        mask = (ion_z_single >= -threshold_middle) & (ion_z_single <= threshold_middle)\n",
    "        if mask.any():\n",
    "            middle_points = np.argwhere((ion_z_single >= -threshold_middle) & (ion_z_single <= threshold_middle))\n",
    "            for middle_p in middle_points:\n",
    "                try:\n",
    "                    if np.sign(ion_z_single[middle_p-threshold_time]) != np.sign(ion_z_single[middle_p+threshold_time]):\n",
    "                        permeation_event += 1\n",
    "                        break\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "    columb_e_conv = 6.242E18\n",
    "    vmemb = 0.2\n",
    "    conductance = permeation_event / columb_e_conv / (time * 1e-9) / vmemb * 1e12\n",
    "    conductance_list.append(conductance)\n",
    "ef_data['conductance_cla'] = conductance_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ef_data['note'] = ef_data['note'].apply(lambda x: 'EF_200' if x.find('EF_200')>=0 else 'EF_n200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ef_data.loc[ef_data.system == 2, 'ligand'] = 'NACHRA7_NOPNU_EPJ_POPC_nca'\n",
    "ef_data.loc[ef_data.system == 3, 'ligand'] = 'NACHRA7_NOPNU_EPJ_POPC_nca'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ef_data['conductance_sum'] = ef_data['conductance_sod'] + ef_data['conductance_cla']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(24,10))\n",
    "\n",
    "l_box = sns.boxplot(x=ef_data['ligand'].to_numpy(),\n",
    "            y=ef_data['conductance_sum'].to_numpy(),\n",
    "            ax=ax,\n",
    "            hue=ef_data['note'].to_numpy(),\n",
    "            palette=['#6e6d59',cmap_open(cmap_open.N)],\n",
    "            dodge=True,\n",
    "            #width=0.6,\n",
    "            linewidth=2.5,\n",
    "            order=['NACHRA7_EPJ_POPC','NACHRA7_NOPNU_EPJ_POPC','NACHRA7_NOPNU_EPJ_POPC_nca', 'NACHRS7_NOPNU_EPJ_POPC_NOECD','NACHRS7_NOPNU_EPJ_POPC_NOICD','NACHRA7_E97A_NOPNU_EPJ_POPC'])\n",
    "sns.swarmplot(x=ef_data['ligand'].to_numpy(),\n",
    "              y=ef_data['conductance_sum'].to_numpy(),\n",
    "              size=10,\n",
    "              ax=ax,\n",
    "              palette=[cmap_open(0),cmap_open(cmap_open.N)],\n",
    "              hue=ef_data['note'].to_numpy(),\n",
    "              dodge=True,\n",
    "              order=['NACHRA7_EPJ_POPC','NACHRA7_NOPNU_EPJ_POPC','NACHRA7_NOPNU_EPJ_POPC_nca','NACHRS7_NOPNU_EPJ_POPC_NOECD','NACHRS7_NOPNU_EPJ_POPC_NOICD','NACHRA7_E97A_NOPNU_EPJ_POPC'])\n",
    "\n",
    "ax.set_ylabel('Absolute Conductance (pS)')\n",
    "ax.set_xticklabels(['Desensitizing \\nw/o bound Ca$^{2+}$','Activating \\nw/ bound Ca$^{2+}$', 'Activating \\nw/o bound Ca$^{2+}$', 'Activating \\nw/o ECD','Activating \\nw/o ICD','Activating \\nE97A'])\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[2:], ['200 mV', '-200 mV'])\n",
    "\n",
    "l_box.artists[0].set_facecolor('#C78E52')\n",
    "l_box.artists[1].set_facecolor('#C78E52')\n",
    "\n",
    "set_axis_boarder(ax)\n",
    "plt.savefig('Figures/figure_ef.pdf',bbox_inches = 'tight', pad_inches=0.1, transparent=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mda_py38",
   "language": "python",
   "name": "jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
